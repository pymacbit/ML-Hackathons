{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.read_csv('data_dict.csv')\n",
    "\n",
    "train_bureau = pd.read_csv('train_bureau.csv')\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "\n",
    "test_bureau = pd.read_csv('test_bureau.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.rename(columns= {\"InstlmentMode\":'InstalmentMode', \"MaturityDAte\":\"MaturityDate\", \"Top-up Month\":\"TopUpMonth\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['DisbursalDate','MaturityDate']] = train_data[['DisbursalDate','MaturityDate']].apply(pd.to_datetime) \n",
    "train_data['LoanDuration'] = (train_data['MaturityDate'] - train_data['DisbursalDate']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get correlations of each features in dataset\n",
    "corrmat = train_data.corr()\n",
    "plt.figure(figsize=(10,6))\n",
    "cmap = sns.diverging_palette(0, 230, 70, 60, as_cmap=True)\n",
    "sns.heatmap(corrmat, annot=True, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_data(data):\n",
    "    Null = pd.Series(data.isnull().sum())\n",
    "    Unique_Count = pd.Series(data.describe(include='all',datetime_is_numeric=True).loc['unique', :])\n",
    "    Data_type = pd.Series(data.dtypes)\n",
    "    info_abt_data = pd.DataFrame(({\"Null\":Null, \"Unique Count\": Unique_Count, \"Data type\": Data_type}))\n",
    "    return info_abt_data\n",
    "\n",
    "info_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_data(df):\n",
    "    columns_with_null = df.columns[df.isna().sum() > 0]\n",
    "    null_pct = (df[columns_with_null].isna().sum() / df.shape[0]).sort_values(ascending=False) * 100\n",
    "    plt.figure(figsize=(8,6));\n",
    "    sns.barplot(y = null_pct.index, x = null_pct, orient='h')\n",
    "    plt.title('% Na values in dataframe by columns');\n",
    "    \n",
    "plot_missing_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop([\"Area\", \"City\", \"ZiPCODE\", \"SEX\", \"AssetID\", \"State\", 'AuthDate', 'DisbursalDate', 'MaturityDate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['TopUpMonth']= train_data['TopUpMonth'].replace({'No Top-up Service':0, '12-18 Months':1, '18-24 Months':2, '24-30 Months':3, '30-36 Months': 4, '36-48 Months':5, ' > 48 Months':6 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['PaymentMode'] = train_data['PaymentMode'].replace(' ', '_', regex=True)\n",
    "train_data['PaymentMode'] = train_data['PaymentMode'].replace('_', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['PaymentMode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.AGE.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.MonthlyIncome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_data[\"AGE\"] = pd.DataFrame(imputer.fit_transform(train_data[[\"AGE\"]]))\n",
    "train_data[\"MonthlyIncome\"] = pd.DataFrame(imputer.fit_transform(train_data[[\"MonthlyIncome\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"LoanDuration\"] = pd.DataFrame(imputer.fit_transform(train_data[[\"LoanDuration\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-dinner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minor-appointment",
   "metadata": {},
   "source": [
    "--------------\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data)\n",
    "\n",
    "train_data\n",
    "\n",
    "X = train_data.drop(['TopUpMonth','ID'], axis = 1)\n",
    "y = train_data['TopUpMonth'] \n",
    "\n",
    "\n",
    "print(\"Data For Training model\\n\\n\",\"Input data: \", X.shape, \"\\n\", \"Output data: \",y.shape)\n",
    "\n",
    "X.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "print(\"Training Data :\",\"X_train:\", X_train.shape, \"--- y_train:\", y_train.shape,\"\\nTesting Data  :\" \" X_test:\",X_test.shape, \" --- y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# define the model\n",
    "model_xgbc = XGBClassifier()\n",
    "# fit the model on train data\n",
    "model_xgbc.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat_xgbc = model_xgbc.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat_xgbc)\n",
    "print(\"---------------------------------------------\")\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print(\"---------------------------------------------\")\n",
    "print(classification_report(y_test,yhat_xgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-spyware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-server",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def compute_score(clf, X, y, scoring='accuracy'):\n",
    "    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n",
    "    return np.mean(xval)\n",
    "\n",
    "def recover_train_test_target():\n",
    "    global combined, data_train\n",
    "    targets = data_train['Loan_Status'].map({'Y':1,'N':0})\n",
    "    train = combined.head(614)\n",
    "    test = combined.iloc[614:]\n",
    "    return train, test, targets\n",
    "\n",
    "train, test, targets = recover_train_test_target()\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n",
    "clf = clf.fit(train, targets)\n",
    "\n",
    "features = pd.DataFrame()\n",
    "features['Feature'] = train.columns\n",
    "features['Importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['Importance'], ascending=False, inplace=True)\n",
    "features.set_index('Feature', inplace=True)\n",
    "\n",
    "features.plot(kind='bar', figsize=(20, 10))\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "train_reduced = model.transform(train)\n",
    "train_reduced.shape\n",
    "\n",
    "\n",
    "test_reduced = model.transform(test)\n",
    "test_reduced.shape\n",
    "\n",
    "parameters = {'bootstrap': False,\n",
    "              'min_samples_leaf': 3,\n",
    "              'n_estimators': 50,\n",
    "              'min_samples_split': 10,\n",
    "              'max_features': 'sqrt',\n",
    "              'max_depth': 6}\n",
    "\n",
    "model = RandomForestClassifier(**parameters)\n",
    "model.fit(train, targets)\n",
    "\n",
    "\n",
    "compute_score(model, train, targets, scoring='accuracy')\n",
    "\n",
    "\n",
    "output = model.predict(test).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "aux = pd.read_csv('test.csv')\n",
    "df_output['Loan_ID'] = aux['Loan_ID']\n",
    "df_output['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(output)\n",
    "df_output[['Loan_ID','Loan_Status']].to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-devices",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-hunger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X=train.drop(['loan_default'],axis=1)\n",
    "Y=train['loan_default']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "random_state=42\n",
    "lgb_params = {\n",
    "    \"objective\" : \"binary\",\n",
    "    \"metric\" : \"auc\",\n",
    "    \"boosting\": 'gbdt',\n",
    "    \"max_depth\" : -1,\n",
    "    \"num_leaves\" : 13,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"bagging_fraction\" : 0.4,\n",
    "    \"feature_fraction\" : 0.05,\n",
    "    \"min_data_in_leaf\": 80,\n",
    "    \"min_sum_heassian_in_leaf\": 10,\n",
    "    \"tree_learner\": \"serial\",\n",
    "    \"boost_from_average\": \"false\",\n",
    "    #\"lambda_l1\" : 5,\n",
    "    #\"lambda_l2\" : 5,\n",
    "    \"bagging_seed\" : random_state,\n",
    "    \"verbosity\" : 1,\n",
    "    \"seed\": random_state\n",
    "}\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "predictions = test[['UniqueID']]\n",
    "val_aucs = []\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    \n",
    "    N = 5\n",
    "    p_valid,yp = 0,0\n",
    "    for i in range(N):\n",
    "#         X_t, y_t = (X_train, y_train)\n",
    "#         X_t = pd.DataFrame(X_t)\n",
    "#         X_t = X_t.add_prefix('var_')\n",
    "    \n",
    "        trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val)\n",
    "      \n",
    "        evals_result = {}\n",
    "        lgb_clf = lgb.train(lgb_params,\n",
    "                        trn_data,\n",
    "                        100000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        early_stopping_rounds=3000,\n",
    "                        verbose_eval = 1000,\n",
    "                        evals_result=evals_result\n",
    "                       )\n",
    "        p_valid += lgb_clf.predict(X_val)\n",
    "        yp += lgb_clf.predict(test)\n",
    "    val_score = roc_auc_score(y_val, p_valid)\n",
    "    val_aucs.append(val_score)\n",
    "    \n",
    "#     predictions['fold{}'.format(fold+1)] = yp/N\n",
    "\n",
    "\n",
    "predictions['loan_status']=yp/5\n",
    "\n",
    "predictions.to_csv('submission.csv',index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
